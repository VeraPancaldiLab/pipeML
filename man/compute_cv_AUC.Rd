% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/machine_learning.R
\name{compute_cv_AUC}
\alias{compute_cv_AUC}
\title{Compute Cross-Validated AUC Values for Machine Learning Models}
\usage{
compute_cv_AUC(
  models,
  file_name = NULL,
  base_models = FALSE,
  AUC_type = "AUROC",
  return = TRUE
)
}
\arguments{
\item{models}{A named list of trained machine learning models. Each model should contain a \code{resample}
data frame with AUROC and AUPRC values from cross-validation.}

\item{file_name}{(Optional) Character string. Used as the prefix for the plot filenames if \code{save_plot = TRUE}.}

\item{base_models}{Logical. If \code{TRUE}, selects a subset of models as base learners for stacking using the \code{choose_base_models()} function.}

\item{AUC_type}{Character. Either \code{"AUROC"} or \code{"AUPRC"}; determines which metric is used to select the top-performing model.}

\item{return}{Logical. Whether to return the results and generated plots.}
}
\value{
A list containing:
\describe{
\item{\code{AUROC}}{A data frame with median and standard deviation of AUROC values for each model.}
\item{\code{AUPRC}}{A data frame with median and standard deviation of AUPRC values for each model.}
\item{\code{Top_model}}{The name of the model with the highest median value for the selected metric (\code{AUC_type}).}
\item{\code{Base_models}}{(Optional) A character vector of selected base models for stacking, returned if \code{base_models = TRUE}.}
}
}
\description{
This function computes cross-validated AUROC and AUPRC scores for a list of trained machine learning models.
It can also save performance barplots and optionally select base models for stacking.
}
\examples{
\dontrun{
res <- compute_cv_AUC(
  models = ml_models,
  file_name = "Model_Performance",
  base_models = TRUE,
  AUC_type = "AUROC",
  save_plot = TRUE
)
}
}
