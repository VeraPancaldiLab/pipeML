% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/machine_learning.R
\name{compute_k_fold_CV}
\alias{compute_k_fold_CV}
\title{Perform repeated stratified k-fold cross-validation for model training and tuning}
\usage{
compute_k_fold_CV(
  model,
  k_folds,
  n_rep,
  stacking = FALSE,
  metric = "Accuracy",
  boruta,
  boruta_iterations = NULL,
  fix_boruta = NULL,
  tentative = FALSE,
  boruta_threshold = NULL,
  file_name = NULL,
  LODO = FALSE,
  ncores = NULL,
  return = FALSE
)
}
\arguments{
\item{model}{A data frame containing features and a target column named 'target' corresponding to the response variable to predict.}

\item{k_folds}{Integer. Number of folds for k-fold cross-validation. Default is 5.}

\item{n_rep}{Integer. Number of repetitions of the k-fold cross-validation. Default is 100.}

\item{stacking}{Logical. Whether to perform model stacking. Default is FALSE.}

\item{metric}{Character. Metric used for hyperparameter tuning and model evaluation. Supported values are "Accuracy", "AUROC", and "AUPRC".}

\item{boruta}{Logical. Whether to apply Boruta for feature selection before model training. Note that many ML models handle feature importance internally, so prior selection is optional unless multicollinearity is a concern. Default is FALSE.}

\item{boruta_iterations}{Integer. Number of iterations to run Boruta. Since Boruta involves randomness, repeated runs improve consistency. Default is 100.}

\item{fix_boruta}{Logical. Whether to fix Borutaâ€™s internal parameters. See \code{compute_boruta()} for details.}

\item{tentative}{Logical. Whether to include tentative features as confirmed in the training dataset.}

\item{boruta_threshold}{Numeric. Threshold for confirming features after multiple Boruta iterations. For example, 0.8 means features must be confirmed in at least 80\% of iterations. Default is 0.8.}

\item{file_name}{Character. File name used for saving output plots in the \verb{Results/} directory.}

\item{LODO}{Logical. If TRUE, performs Leave-One-Dataset-Out (LODO) cross-validation by stratifying folds based on cohort membership.}

\item{ncores}{Integer. Number of cores to use for parallelization. If not given, detectCores() - 1 will be used.}

\item{return}{Logical. Whether to return the results and generated plots.}
}
\value{
A list containing:
\itemize{
\item Features used during training
\item The selected machine learning model
\item All trained machine learning models
}

If \code{stacking = TRUE}, the list will also include:
\itemize{
\item Base models
\item Meta-learner
\item Matrix of weighted feature importance (see \code{calculate_feature_importance_stacking()})
}
}
\description{
This function performs repeated stratified k-fold cross-validation on a dataset to train and tune hyperparameters for 13 machine learning methods. Optionally, it can also perform model stacking and Boruta-based feature selection. Performance is evaluated using user-specified metrics such as Accuracy, AUROC, or AUPRC.
}
